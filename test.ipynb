{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will need to have set up:\n",
      "- Docker desktop\n",
      "- Anaconda or miniconda python\n",
      "- Database access tool: datagrip or DBeaver\n",
      "- Vs code for python development (3.10 or higher)\n",
      "- Github\n",
      "- AWS account (amazon web services)\n",
      "Review topics:\n",
      "- Terminal commands\n",
      "- Docker and docker compose\n",
      "- Basics of docker filers and docker-compose.yaml files\n",
      "- Setting up volumes and mapping between host and guest OS\n",
      "1/8/25\n",
      "Foundations\n",
      "- Searching is the most common operation performed by a database system\n",
      "- SELECT is the most versatile/complex\n",
      "- Baseline for efficiency is Linear Search\n",
      "- Starts at the beginning of a list and proceed element by element until:\n",
      "- You find what you're looking for\n",
      "- You get to the last element and haven't found it\n",
      "- Record\n",
      "- Collection of values for attributes of a single entity instance; a row of a table\n",
      "- Collection\n",
      "- A set of records of the same entity type; a table\n",
      "- Trivally, store in some sequential order like a list\n",
      "- Search Key - A value for an attribute from the entity type\n",
      "- Could be >= 1 attribute\n",
      "Lists of records\n",
      "- If each record takes up x bytes of memory, then for n record, we n eed n*x bytes of\n",
      "memory\n",
      "- Contiguously allocated list\n",
      "- All n*x bytes are allocated as a single “chunk” of memory\n",
      "- Linked list\n",
      "- Each record needs x bytes +additional space for 1 or 2 memory addresses\n",
      "- Individual record are linked together in a type of chain using memory addresses\n",
      "- Contiguous vs linked\n",
      "-\n",
      "Pros and Cons\n",
      "- Arrays are faster for random access, but slow for inserting anywhere but the end\n",
      "-\n",
      "- Linked lists are faster for inserting anywhere in the list, but slower for random access\n",
      "-\n",
      "Observations\n",
      "- Arrays\n",
      "- Fast for random access\n",
      "- Slow for random insertions\n",
      "- Linked Lists\n",
      "- Slow for random access\n",
      "- Fast for random insertions\n",
      "Binary Search\n",
      "- Input\n",
      "- Array of values in sorted order, target value\n",
      "- Output\n",
      "- The location (index) of where target is located or some value indicating target was\n",
      "not found\n",
      "-\n",
      "Time Complexity\n",
      "- Linear Search\n",
      "- Best Case:\n",
      "- Target is found at the first element; only one comparison\n",
      "- Worst case:\n",
      "- Target is not in the array; n comparison\n",
      "- Therefore, in the worst case, linear search is O(n) time complexity.\n",
      "- Binary Search\n",
      "- Cant perform on an unsorted array\n",
      "- Best Case:\n",
      "- Target is found at mid; 1 comparison (inside the loop)\n",
      "- Worst Case:\n",
      "- Target is not in the array; log2 n comparisons\n",
      "- Therefore, in the worst case, binary search is O(log2n) time complexity.\n",
      "Database Searching\n",
      "- Assume data is stored on disk by column id’s value\n",
      "- Searching for a specific id = fast\n",
      "- What do we want to search for a specific specialVal?\n",
      "- Only option is linear scan of that column\n",
      "- Can't store data on disk sorted by both id and specialVal (at the same time)\n",
      "- Data would have to be duplicated → space inefficient\n",
      "-\n",
      "- We need on external data structure to support faster searching by specialVal than a linear\n",
      "scan\n",
      "What do we have in our arsenal?\n",
      "1) An array of tuples specialVal, rowNumber) sorted by specialVal\n",
      "a) We could use Binary Search to quickly locate a particular specialVal and find its\n",
      "corresponding row in the table\n",
      "b) But, every insert into the table would be like inserting into a sorted array - slow…\n",
      "2) A linked list of tuples (specialVal, rowNumber) sorted by specialVal\n",
      "a) searching for a specialVal would be slow - linear scan required\n",
      "b) But inserting into the table would theoretically be quick to also add to the list\n",
      "Something with fast insert and fast search\n",
      "- Binary search tree\n",
      "- A binary tree where every node in the tree left subtree is less than its parent and\n",
      "every node in the right subtree is greater than its parent\n",
      "- Needs to be sorted\n",
      "-\n",
      "1/13/25\n",
      "AVL tree rotation notes\n",
      "AVL Trees Notes\n",
      "AVL trees are self-balancing binary search trees where the height difference between left and\n",
      "right subtrees (the balance factor) of any node is at most 1. This balancing property ensures\n",
      "operations like search, insert, and delete maintain O(log n) time complexity.\n",
      "## Core Concepts\n",
      "### 1. Balance Factor\n",
      "- **Definition**: height(right subtree) - height(left subtree)\n",
      "- **Valid values**: -1, 0, or 1 for an AVL tree\n",
      "- When the balance factor becomes -2 or 2, rebalancing is required\n",
      "### 2. Tree Operations\n",
      "- **Search**: Same as in a regular binary search tree\n",
      "- **Insert**: Insert as in a binary search tree, then rebalance if needed\n",
      "- **Delete**: Delete as in a binary search tree, then rebalance if needed\n",
      "## Insertion Process\n",
      "1. **Standard BST Insertion**: Insert the new node like in a regular binary search tree\n",
      "2. **Update Heights**: Recalculate heights of affected nodes along the path from the insertion\n",
      "point up to the root\n",
      "3. **Check Balance Factors**: Identify nodes with balance factors outside the -1 to 1 range\n",
      "4. **Rebalancing**: Apply appropriate rotation(s) to restore balance\n",
      "## Rotations\n",
      "### 1. Left Rotation\n",
      "Used when a node has a balance factor of +2 (right-heavy)\n",
      "```\n",
      "A B\n",
      "/ \\ / \\\n",
      "X B -> A Z\n",
      "/ \\ / \\\n",
      "Y Z X Y\n",
      "```\n",
      "### 2. Right Rotation\n",
      "Used when a node has a balance factor of -2 (left-heavy)\n",
      "```\n",
      "A B\n",
      "/ \\ / \\\n",
      "B Z -> X A\n",
      "/ \\ / \\\n",
      "X Y Y Z\n",
      "```\n",
      "### 3. Left-Right Rotation (Double Rotation)\n",
      "When a node's left child is right-heavy\n",
      "```\n",
      "A A Y\n",
      "/ \\ / \\ / \\\n",
      "B Z -> Y Z -> B A\n",
      "/ \\ / \\ / \\\n",
      "X Y B Q X Z\n",
      "/ \\ / \\\n",
      "P Q X P\n",
      "```\n",
      "### 4. Right-Left Rotation (Double Rotation)\n",
      "When a node's right child is left-heavy\n",
      "```\n",
      "A A Y\n",
      "/ \\ / \\ / \\\n",
      "X B -> X Y -> A B\n",
      "/ \\ / \\ / \\\n",
      "Y Z P B X Z\n",
      "/ \\ / \\\n",
      "P Q Q Z\n",
      "```\n",
      "## Insertion Rebalancing Cases\n",
      "1. **Left-Left Case**: A node becomes unbalanced with balance factor -2, and its left child has\n",
      "balance factor -1 or 0\n",
      "- **Solution**: Single right rotation\n",
      "2. **Right-Right Case**: A node becomes unbalanced with balance factor +2, and its right child\n",
      "has balance factor +1 or 0\n",
      "- **Solution**: Single left rotation\n",
      "3. **Left-Right Case**: A node becomes unbalanced with balance factor -2, and its left child has\n",
      "balance factor +1\n",
      "- **Solution**: Left rotation on the left child, then right rotation on the unbalanced node\n",
      "4. **Right-Left Case**: A node becomes unbalanced with balance factor +2, and its right child\n",
      "has balance factor -1\n",
      "- **Solution**: Right rotation on the right child, then left rotation on the unbalanced node\n",
      "## Step-by-Step Insertion Algorithm\n",
      "1. Insert the new node as in a regular BST\n",
      "2. Start from the newly inserted node and move up to the root:\n",
      "- Update the height of each node\n",
      "- Calculate the balance factor of each node\n",
      "- If the balance factor becomes -2 or +2, identify the case and apply appropriate rotation(s)\n",
      "3. Continue this process all the way to the root\n",
      "## Example\n",
      "Let's insert values [10, 20, 30, 40, 50] into an initially empty AVL tree:\n",
      "1. Insert 10: Tree is balanced\n",
      "```\n",
      "10\n",
      "```\n",
      "2. Insert 20: Tree is still balanced\n",
      "```\n",
      "10\n",
      "\\\n",
      "20\n",
      "```\n",
      "3. Insert 30: Tree becomes right-heavy, needs left rotation at root\n",
      "```\n",
      "10 20\n",
      "\\ / \\\n",
      "20 -> 10 30\n",
      "\\\n",
      "30\n",
      "```\n",
      "4. Insert 40: Tree becomes right-heavy at node 30\n",
      "```\n",
      "20 20\n",
      "/ \\ / \\\n",
      "10 30 -> 10 40\n",
      "\\ /\n",
      "40 30\n",
      "```\n",
      "5. Insert 50: Tree becomes right-heavy at node 40, requires left rotation\n",
      "```\n",
      "20 20\n",
      "/ \\ / \\\n",
      "10 40 10 40\n",
      "/ \\ -> / \\\n",
      "30 50 30 50\n",
      "```\n",
      "## Implementation Tips\n",
      "1. Maintain a height field in each node\n",
      "2. After inserting, trace back from the insertion point to the root\n",
      "3. Recalculate heights and balance factors at each step\n",
      "4. Apply rotations when needed\n",
      "5. Continue this process up to the root\n",
      "## Pseudocode for AVL Tree Insertion\n",
      "```\n",
      "function insert(root, key):\n",
      "if root is null:\n",
      "return new Node(key)\n",
      "if key < root.key:\n",
      "root.left = insert(root.left, key)\n",
      "else if key > root.key:\n",
      "root.right = insert(root.right, key)\n",
      "else:\n",
      "return root // Duplicate keys not allowed\n",
      "// Update height of this ancestor node\n",
      "root.height = 1 + max(height(root.left), height(root.right))\n",
      "// Get the balance factor\n",
      "balance = getBalance(root)\n",
      "// Left-Left Case\n",
      "if balance < -1 and key < root.left.key:\n",
      "return rightRotate(root)\n",
      "// Right-Right Case\n",
      "if balance > 1 and key > root.right.key:\n",
      "return leftRotate(root)\n",
      "// Left-Right Case\n",
      "if balance < -1 and key > root.left.key:\n",
      "root.left = leftRotate(root.left)\n",
      "return rightRotate(root)\n",
      "// Right-Left Case\n",
      "if balance > 1 and key < root.right.key:\n",
      "root.right = rightRotate(root.right)\n",
      "return leftRotate(root)\n",
      "return root\n",
      "```\n",
      "## Rotation Functions\n",
      "```\n",
      "function rightRotate(y):\n",
      "x = y.left\n",
      "T2 = x.right\n",
      "// Perform rotation\n",
      "x.right = y\n",
      "y.left = T2\n",
      "// Update heights\n",
      "y.height = 1 + max(height(y.left), height(y.right))\n",
      "x.height = 1 + max(height(x.left), height(x.right))\n",
      "return x\n",
      "function leftRotate(x):\n",
      "y = x.right\n",
      "T2 = y.left\n",
      "// Perform rotation\n",
      "y.left = x\n",
      "x.right = T2\n",
      "// Update heights\n",
      "x.height = 1 + max(height(x.left), height(x.right))\n",
      "y.height = 1 + max(height(y.left), height(y.right))\n",
      "return y\n",
      "```\n",
      "B+ Tree Notes\n",
      "Key Concepts\n",
      "- **B+ Tree**: A balanced tree data structure that maintains sorted data for efficient insertions,\n",
      "deletions, and searches\n",
      "- **Order (m)**: Defines the maximum number of children a node can have (in these examples,\n",
      "m=4)\n",
      "- **Node Types**:\n",
      "- **Leaf Nodes**: Store actual keys and data values\n",
      "- **Internal Nodes**: Store keys and pointers to child nodes\n",
      "- **Root Node**: The top-level node (can be either a leaf or internal node)\n",
      "## Important Properties\n",
      "- Leaf nodes are connected in a doubly linked list for efficient range queries\n",
      "- Internal nodes store keys as guides for traversal but don't store data\n",
      "- Every node except root must be at least half full\n",
      "- All leaf nodes appear at the same level (balanced tree)\n",
      "## Insertion Process\n",
      "1. **Start at the root** and traverse down to the appropriate leaf node\n",
      "2. **Insert the key** in sorted order within the leaf node\n",
      "3. **If the node is full** (contains m-1 keys):\n",
      "- Split the node into two nodes\n",
      "- Redistribute keys between the original and new node\n",
      "- For leaf nodes: Copy the smallest key from new node up to parent\n",
      "- For internal nodes: Move (not copy) the middle element to parent\n",
      "4. **If parent becomes full**, repeat the split process upward\n",
      "## Node Splitting Rules\n",
      "- **For Leaf Nodes**:\n",
      "- Original node keeps ⌈m/2⌉ keys (ceiling of m/2)\n",
      "- New node gets remaining keys\n",
      "- Smallest key in new node is copied up to parent\n",
      "- New node is linked into the leaf node chain\n",
      "- **For Internal Nodes**:\n",
      "- Middle key moves up to parent (not copied)\n",
      "- Keys less than middle stay in original node\n",
      "- Keys greater than middle go to new node\n",
      "## Step-by-Step Example (m=4)\n",
      "### Initial Insertions: 42, 21, 63, 89\n",
      "- Start with a single leaf node that is also the root: [21, 42, 63, 89]\n",
      "### Insert 35\n",
      "- Leaf node is full, needs to split\n",
      "- Original node: [21, 35]\n",
      "- New node: [42, 63, 89]\n",
      "- Create new parent (root) node with key 42\n",
      "- Tree structure becomes:\n",
      "```\n",
      "[42]\n",
      "/ \\\n",
      "[21,35] [42,63,89]\n",
      "```\n",
      "### Insert 10, 27, 96\n",
      "- These insertions don't cause splits\n",
      "- Tree becomes:\n",
      "```\n",
      "[42]\n",
      "/ \\\n",
      "[10,21,27,35] [42,63,89,96]\n",
      "```\n",
      "### Insert 30\n",
      "- Left leaf node is full, needs to split\n",
      "- Original node: [10, 21]\n",
      "- New node: [27, 30, 35]\n",
      "- Copy 27 up to parent\n",
      "- Tree becomes:\n",
      "```\n",
      "[27,42]\n",
      "/ | \\\n",
      "[10,21] [27,30,35] [42,63,89,96]\n",
      "```\n",
      "### Insert 37 (when root is full)\n",
      "- Causes a leaf node to split, which pushes a new key to the root\n",
      "- Root becomes full and must split\n",
      "- Tree grows one level deeper\n",
      "- Process:\n",
      "1. Split the appropriate leaf node\n",
      "2. When this causes the root to split:\n",
      "- Create new root\n",
      "- Move middle element from old root to new root\n",
      "- Redistribute remaining keys\n",
      "3. Tree becomes a 3-level tree\n",
      "## Key Differences Between B-Tree and B+ Tree\n",
      "- In B+ Tree, all data is stored in leaf nodes\n",
      "- Internal nodes only store keys for navigation\n",
      "- Leaf nodes are linked for sequential access\n",
      "- Keys may appear in both internal nodes and leaf nodes\n",
      "1/27/25\n",
      "Moving beyond the relational model\n",
      "Benefits of the relational model\n",
      "- (mostly) standard data model and Query Language\n",
      "- ACID compliance\n",
      "- Atomicity, consistency, isolation, durability\n",
      "- Works well with highly structured data\n",
      "- Can handle large amounts of data\n",
      "- Well understood, lots of tooling, lots of experience\n",
      "Relationa; database performance\n",
      "- Many ways that a RDBMS increases efficiency:\n",
      "- Indexing (topic we focuses on)\n",
      "- Directly controlling storage\n",
      "- Column oriented storage vs row storage\n",
      "- Query optimization\n",
      "- caching/prefetching\n",
      "- Materialized views\n",
      "- Precompiled stored procedures\n",
      "- Data replication and partitioning\n",
      "Transaction Processing\n",
      "- Transaction\n",
      "- A sequence of one or more of the CRUD operations performed as a single, logical\n",
      "unit of work\n",
      "- Either the entire sequence succeeds (COMMIT)\n",
      "- OR the entire sequence fails (ROLLBACK or ABORT)\n",
      "- Help ensure\n",
      "- Data integrity\n",
      "- Error recovery\n",
      "- Concurrency control\n",
      "- Reliable data storage\n",
      "- Simplified error handling\n",
      "ACID Properties\n",
      "- Atomicity\n",
      "- Transaction is treated as an atomic unit - it is fully executed or no parts of it are\n",
      "executed\n",
      "- Consistency\n",
      "- A transaction takes a database from one consistent state to another consistent state\n",
      "- Consistent state - all data meets integrity constraints\n",
      "- Isolation\n",
      "- Two transactions T1 and T2 are being executed at the same time but cannot affect\n",
      "each other\n",
      "- If both T1 and T2 are reading the data - no problem\n",
      "- If T1 is reading the same data that T2 may be writing, can result in:\n",
      "- Dirty Read\n",
      "- a transaction T1 is able to read a row that has been modified by\n",
      "another transaction T2 that hasn’t yet executed a COMMIT\n",
      "-\n",
      "- Non-repeatable Read\n",
      "- two queries in a single transaction T1 execute a SELECT but get\n",
      "different values because another transaction T2 has changed data\n",
      "and COMMITTED\n",
      "-\n",
      "- Phantom Reads\n",
      "- when a transaction T1 is running and another transaction T2 adds\n",
      "or deletes rows from the set T1 is using\n",
      "-\n",
      "- Durability\n",
      "- Once a transaction is completed and committed successfully, its changes are\n",
      "permanent\n",
      "- Even in the event of a system failure, committed transactions are preserved\n",
      "But…\n",
      "- Relational databases may not be the solution to all problems…\n",
      "- sometimes, schemas evolve over time\n",
      "- not all apps may need the full strength of ACID compliance\n",
      "- joins can be expensive\n",
      "- a lot of data is semi-structured or unstructured (JSON, XML, etc)\n",
      "- Horizontal scaling presents challenges\n",
      "- some apps need something more performant (real time, low latency systems)\n",
      "Scalability - Up or Out?\n",
      "- Conventional Wisdom:\n",
      "- Scale vertically (up, with bigger, more powerful systems) until the demands of\n",
      "high-availability make it necessary to scale out with some type of distributed\n",
      "computing model\n",
      "- But why? Scaling up is easier - no need to really modify your architecture. But there are\n",
      "practical and financial limits\n",
      "- However:\n",
      "- There are modern systems that make horizontal scaling less problematic.\n",
      "-\n",
      "So what? Distributed data when scaling out\n",
      "- A distributed system is a collection of independent computers that appear to its users as\n",
      "one computer\n",
      "- Characteristics of distributed systems:\n",
      "- Computers operate concurrently\n",
      "- Computers fail independently\n",
      "- No shared global clock\n",
      "Distributed storage - 2 directions\n",
      "-\n",
      "Distributed data stores\n",
      "- Data is stored on > 1 node, typically replicated\n",
      "- i.e. each block of data is available on N nodes\n",
      "- Distributed databases can be relational or non-relational\n",
      "- MySQL and PostgreSQL support replication and sharding\n",
      "- CockroachDB - new player on the scene\n",
      "- Many NoSQL systems support one or both models\n",
      "- But remember: Network partitioning is inevitable!\n",
      "- network failures, system failures\n",
      "- Overall system needs to be Partition Tolerant\n",
      "- System can keep running even w/ network partition\n",
      "The CAP Theorm\n",
      "- The CAP Theorem states that it is impossible for a distributed data store to\n",
      "simultaneously provide more than two out of the following three guarantees:\n",
      "- Consistency - Every read receives the most recent write or error thrown\n",
      "- Availability - Every request receives a (non-error) response - but no guarantee\n",
      "that the response contains the most recent write\n",
      "- Partition Tolerance - The system can continue to operate despite arbitrary\n",
      "network issues.\n",
      "CAP Theorom - database view\n",
      "- Consistency*: Every user of the DB has an identical view of the data at any given instant\n",
      "- *note, the definition of consistency in cap is different from that of ACID\n",
      "- Availability: In the event of a failure, the database remains operational\n",
      "- Partition Tolerance: The database can maintain operations in the event of the network’s\n",
      "failing between two segments of the distributed system\n",
      "- Consistency + Availability: System always responds with the latest data and every\n",
      "request gets a response, but may not be able to deal with network issues\n",
      "- Consistency + Partition Tolerance: If system responds with data from a distributed store,\n",
      "it is always the latest, else data request is dropped.\n",
      "- Availability + Partition Tolerance: System always sends are responds based on distributed\n",
      "store, but may not be the absolute latest data.\n",
      "-\n",
      "CAP in reality\n",
      "- What it is really saying\n",
      "- If you cannot limit the number of faults, requests can be directed to any server,\n",
      "and you insist on serving every request, then you cannot possibly be consistent.\n",
      "- But it is interpreted as\n",
      "- You must always give up something: consistency, availability, or tolerance to\n",
      "failure.\n",
      "2/3/25\n",
      "noSQL and KV dbs\n",
      "Distributed DBs and ACID - Pessimistic concurrency\n",
      "- ACID transactions\n",
      "- Focuses on “data safety”\n",
      "- considered a pessimistic concurrency model because it assumes one transaction\n",
      "has to protect itself from other transactions\n",
      "- IOW, it assumes that if something can go wrong, it will.\n",
      "- Conflicts are prevented by locking resources until a transaction is complete (there\n",
      "are both read and write locks)\n",
      "- Write Lock Analogy → borrowing a book from a library… If you have it, no one\n",
      "else can.\n",
      "Optimistic Concurrency\n",
      "- Transactions do not obtain locks on data when they read or write\n",
      "- Optimistic because it assumes conflicts are unlikely to occur\n",
      "- Even if there is a conflict, everything will still be OK.\n",
      "- But how?\n",
      "- Add last update timestamp and version number columns to every table… read\n",
      "them when changing. THEN, check at the end of transaction to see if any other\n",
      "transaction has caused them to be modified.\n",
      "- Low Conflict Systems (backups, analytical dbs, etc.)\n",
      "- Read heavy systems\n",
      "- the conflicts that arise can be handled by rolling back and re-running a transaction\n",
      "that notices a conflict.\n",
      "- So, optimistic concurrency works well - allows for higher concurrency\n",
      "- High Conflict Systems\n",
      "- rolling back and rerunning transactions that encounter a conflict → less efficient\n",
      "- So, a locking scheme (pessimistic model) might be preferable\n",
      "NoSQL\n",
      "- NoSQL” first used in 1998 by Carlo Strozzi to describe his relational database system\n",
      "that did not use SQL.\n",
      "- More common, modern meaning is “Not Only SQL”\n",
      "- But, sometimes thought of as non-relational DBs\n",
      "- Idea originally developed, in part, as a response to processing unstructured web-based\n",
      "data.\n",
      "ACID Alternative for Distrib Systems - BASE\n",
      "- Basically Available\n",
      "- Guarantees the availability of the data (per CAP), but response can be\n",
      "“failure”/“unreliable” because the data is in an inconsistent or changing state\n",
      "- System appears to work most of the time\n",
      "- Soft State - The state of the system could change over time, even w/o input. Changes\n",
      "could be the result of eventual consistency.\n",
      "- Data stores don’t have to be write-consistent\n",
      "- Replicas don’t have to be mutually consistent\n",
      "- Eventual Consistency - The system will eventually become consistent\n",
      "- All writes will eventually stop so all nodes/replicas can be updated\n",
      "Categories of noSQL DBs\n",
      "- Document databases\n",
      "- Graph databases\n",
      "- Key value databases\n",
      "- Column oriented\n",
      "Key value databases\n",
      "- Key-value stores are designed around:\n",
      "- Simplicity\n",
      "- the data model is extremely simple\n",
      "- comparatively, tables in a RDBMS are very complex.\n",
      "- lends itself to simple CRUD ops and API creation\n",
      "- Key = value\n",
      "- Speed\n",
      "- usually deployed as in-memory DB\n",
      "- retrieving a value given its key is typically a O(1) op b/c hash tables or\n",
      "similar data structs used under the hood\n",
      "- no concept of complex queries or joins… they slow things down\n",
      "- Scalability\n",
      "- Horizontal Scaling is simple - add more nodes\n",
      "- Typically concerned with eventual consistency, meaning in a distributed\n",
      "environment, the only guarantee is that all nodes will eventually converge\n",
      "on the same value.\n",
      "KV DS Use cases\n",
      "- EDA/Experimentation Results Store\n",
      "- store intermediate results from data preprocessing and EDA\n",
      "- store experiment or testing (A/B) results w/o prod db\n",
      "- Feature Store\n",
      "- store frequently accessed feature → low-latency retrieval for model training and\n",
      "prediction\n",
      "- Model Monitoring\n",
      "- store key metrics about performance of model, for example, in real-time\n",
      "inferencing.\n",
      "KV SWE Use Cases\n",
      "- Storing Session Information\n",
      "- everything about the current session can be stored via a single PUT or POST and\n",
      "retrieved with a single GET …. VERY Fast\n",
      "- User Profiles & Preferences\n",
      "- User info could be obtained with a single GET operation… language, TZ, product\n",
      "or UI preferences\n",
      "- Shopping Cart Data\n",
      "- Cart data is tied to the user\n",
      "- needs to be available across browsers, machines, sessions\n",
      "- Caching Layer:\n",
      "- In front of a disk-based database\n",
      "Redis Db\n",
      "- Redis (Remote Directory Server)\n",
      "- Open source, in-memory database\n",
      "- Sometimes called a data structure store\n",
      "- Primarily a KV store, but can be used with other models: Graph, Spatial, Full\n",
      "Text Search, Vector, Time Series\n",
      "- From db-engines.com Ranking of KV Stores:\n",
      "-\n",
      "-\n",
      "2/5/2025\n",
      "Redis Data types\n",
      "- Keys:\n",
      "- usually strings but can be any binary sequence\n",
      "- Values:\n",
      "- Strings\n",
      "- Lists (linked lists)\n",
      "- Sets (unique unsorted string elements)\n",
      "- Sorted Sets\n",
      "- Hashes (string → string)\n",
      "- Geospatial data\n",
      "Redis Database and Interaction\n",
      "- Redis provides 16 databases by default\n",
      "- They are numbered 0 to 15\n",
      "- There is no other name associated\n",
      "- Direct interaction with Redis is through a set of commands related to setting and getting\n",
      "k/v pairs (and variations)\n",
      "- Many language libraries available as well.\n",
      "Foundation data Type - String\n",
      "- Sequence of bytes - text, serialized objects, bin arrays\n",
      "- Simplest data type\n",
      "- Maps a string to another string\n",
      "- Use Cases:\n",
      "- caching frequently accessed HTML/CSS/JS fragments\n",
      "- config settings, user settings info, token management\n",
      "- counting web page/app screen views OR rate limiting\n",
      "Hash Type\n",
      "- Value of KV entry is a collection of field-value pairs\n",
      "- Use Cases:\n",
      "- Can be used to represent basic objects/structures\n",
      "- number of field/value pairs per hash is 2^32-1\n",
      "- practical limit: available system resources (e.g. memory)\n",
      "- Session information management\n",
      "- User/Event tracking (could include TTL)\n",
      "- Active Session Tracking (all sessions under one hash key)\n",
      "Hash Commands\n",
      "List Type\n",
      "- Value of KV Pair is linked lists of string values\n",
      "- Use Cases:\n",
      "- implementation of stacks and queues\n",
      "- queue management & message passing queues (producer/consumer model)\n",
      "- logging systems (easy to keep in chronological order)\n",
      "- build social media streams/feeds\n",
      "- message history in a chat application\n",
      "- batch processing by queueing up a set of tasks to be executed sequentially at a\n",
      "later time\n",
      "Linked Lists Crash Course\n",
      "- Sequential data structure of linked nodes (instead of contiguously allocated memory)\n",
      "- Each node points to the next element of the list (except the last one - points to nil/null)\n",
      "- O(1) to insert new value at front or insert new value at end\n",
      "List commands - queue\n",
      "List Commands - Stack\n",
      "List commands - others\n",
      "JSON type\n",
      "- Full support of the JSON standard\n",
      "- Uses JSONPath syntax for parsing/navigating a JSON document\n",
      "- Internally, stored in binary in a tree-structure → fast access to sub elements\n",
      "Set Type\n",
      "- Unordered collection of unique strings (members)\n",
      "- Use Cases:\n",
      "- track unique items (IP addresses visiting a site, page, screen)\n",
      "- primitive relation (set of all students in DS4300)\n",
      "- access control lists for users and permission structures\n",
      "- social network friends lists and/or group membership\n",
      "- Supports set operations!!\n",
      "Set commands\n",
      "\n",
      "2/10/25\n",
      "Document database\n",
      "- A Document Database is a non-relational database that stores data as structured\n",
      "documents, usually in JSON.\n",
      "- They are designed to be simple, flexible, and scalable.\n",
      "What is JSON?\n",
      "- JSON (JavaScript Object Notation)\n",
      "- a lightweight data-interchange format\n",
      "- It is easy for humans to read and write.\n",
      "- It is easy for machines to parse and generate.\n",
      "- JSON is built on two structures:\n",
      "- A collection of name/value pairs. In various languages, this is operationalized as\n",
      "an object, record, struct, dictionary, hash table, keyed list, or associative array.\n",
      "- An ordered list of values. In most languages, this is operationalized as an array,\n",
      "vector, list, or sequence.\n",
      "- These are two universal data structures supported by virtually all modern\n",
      "programming languages\n",
      "- Thus, JSON makes a great data interchange format.\n",
      "JSON Syntax\n",
      "Binary JSON\n",
      "- BSON → Binary JSON\n",
      "- binary-encoded serialization of a JSON-like document structure\n",
      "- supports extended types not part of basic JSON (e.g. Date, BinaryData, etc)\n",
      "- Lightweight - keep space overhead to a minimum\n",
      "- Traversable - designed to be easily traversed, which is vitally important to a\n",
      "document DB\n",
      "- Efficient - encoding and decoding must be efficient\n",
      "- Supported by many modern programming languages\n",
      "XML (eXtensible Markup Language)\n",
      "- Precursor to JSON as data exchange format\n",
      "- XML + CSS → web pages that separated content and formatting\n",
      "- Structurally similar to HTML, but tag set is extensible\n",
      "XML related tools/technologies\n",
      "- Xpath - a syntax for retrieving specific elements from an XML doc\n",
      "- Xquery - a query language for interrogating XML documents; the SQL of XML\n",
      "- DTD - Document Type Definition - a language for describing the allowed structure of an\n",
      "XML document\n",
      "- XSLT - eXtensible Stylesheet Language Transformation - tool to transform XML into\n",
      "other formats, including non-XML formats such as HTML.\n",
      "Why document databases?\n",
      "- Document databases address the impedance mismatch problem between object\n",
      "persistence in OO systems and how relational DBs structure data.\n",
      "- OO Programming → Inheritance and Composition of types.\n",
      "- How do we save a complex object to a relational database? We basically have to\n",
      "deconstruct it.\n",
      "- The structure of a document is self-describing.\n",
      "- They are well-aligned with apps that use JSON/XML as a transport layer\n",
      "Mongo DB\n",
      "- Started in 2007 after Doubleclick was acquired by Google, and 3 of its veterans realized\n",
      "the limitations of relational databases for serving > 400,000 ads per second\n",
      "- MongoDB was short for Humongous Database\n",
      "- MongoDB Atlas released in 2016 → documentdb as a service\n",
      "MongoDB Documents\n",
      "- No predefined schema for documents is needed\n",
      "- Every document in a collection could have different data/schema\n",
      "-\n",
      "-\n",
      "Relational vs Mongo/Document DB\n",
      "MongoDB Features\n",
      "- Rich Query Support - robust support for all CRUD ops\n",
      "- Indexing - supports primary and secondary indices on document fields\n",
      "- Replication - supports replica sets with automatic failover\n",
      "- Load balancing built in\n",
      "Interacting with MongoDB\n",
      "- mongosh → MongoDB Shell\n",
      "- CLI tool for interacting with a MongoDB instance\n",
      "- MongoDB Compass\n",
      "- free, open-source GUI to work with a MongoDB database\n",
      "- DataGrip and other 3rd Party Tools\n",
      "- Every major language has a library to interface with MongoDB\n",
      "- PyMongo (Python), Mongoose (JavaScript/node), …\n",
      "2/12/25\n",
      "Mongodb + pymongo\n",
      "- PyMongo is a Python library for interfacing with MongoDB instances\n",
      "- from pymongo import MongoClient\n",
      "- client = MongoClient(\n",
      "- ‘mongodb://user_name:pw@localhost:27017’\n",
      "- )\n",
      "Getting a database and collection\n",
      "Inserting a Single Document\n",
      "Find all movies from 2000\n",
      "Jupyter Time\n",
      "- Activate your DS4300 conda or venv python environment\n",
      "- Install pymongo with pip install pymongo\n",
      "- Install Jupyter Lab in you python environment\n",
      "- pip install jupyterlab\n",
      "- Download and unzip > this < zip file - contains 2 Jupyter Notebooks\n",
      "- In terminal, navigate to the folder where you unzipped the files, and run jupyter lab\n",
      "More Mongo Notes\n",
      "MongoDB CRUD Operations: Notes, Explanations, and Examples\n",
      "1. Create (Insert Operations)\n",
      "MongoDB allows inserting documents into a collection using insertOne() and\n",
      "insertMany().\n",
      "Example:\n",
      "// Insert a single document\n",
      "db.users.insertOne({ name: \"Alice\", age: 28, city: \"New York\" });\n",
      "// Insert multiple documents\n",
      "db.users.insertMany([\n",
      "{ name: \"Bob\", age: 32, city: \"Los Angeles\" },\n",
      "{ name: \"Charlie\", age: 25, city: \"Chicago\" }\n",
      "]);\n",
      "2. Read (Query Operations)\n",
      "To retrieve data from MongoDB, use find() and findOne().\n",
      "Example:\n",
      "// Find one document\n",
      "db.users.findOne({ name: \"Alice\" });\n",
      "// Find multiple documents with a filter\n",
      "db.users.find({ age: { $gt: 25 } });\n",
      "// Find all documents and format output\n",
      "db.users.find().pretty();\n",
      "Additional Example:\n",
      "// Find theaters in Massachusetts\n",
      "db.theaters.find({\"location.address.state\": \"MA\"}, { \"_id\": 0, \"location.address.street1\": 1,\n",
      "\"location.address.city\": 1, \"location.address.zipcode\":1 });\n",
      "3. Update (Modify Documents)\n",
      "Documents can be updated using updateOne(), updateMany(), and replaceOne().\n",
      "Example:\n",
      "// Update a single document\n",
      "db.users.updateOne({ name: \"Alice\" }, { $set: { age: 29 } });\n",
      "// Update multiple documents\n",
      "db.users.updateMany({ city: \"Chicago\" }, { $set: { state: \"IL\" } });\n",
      "// Replace an entire document\n",
      "db.users.replaceOne({ name: \"Charlie\" }, { name: \"Charlie Brown\", age: 26, city: \"Chicago\" });\n",
      "4. Delete (Remove Documents)\n",
      "Documents can be deleted using deleteOne() and deleteMany().\n",
      "Example:\n",
      "// Delete a single document\n",
      "db.users.deleteOne({ name: \"Alice\" });\n",
      "// Delete multiple documents\n",
      "db.users.deleteMany({ age: { $lt: 30 } });\n",
      "5. Additional Query Operators\n",
      "● $gt (greater than), $lt (less than), $gte (greater than or equal to), $lte (less than or\n",
      "equal to).\n",
      "● $in (matches any value in a list), $ne (not equal).\n",
      "● $or, $and, $not for logical operations.\n",
      "Example:\n",
      "// Find users older than 30 or living in Chicago\n",
      "db.users.find({ $or: [{ age: { $gt: 30 } }, { city: \"Chicago\" }] });\n",
      "6. Counting Documents\n",
      "To count documents matching a query, use countDocuments().\n",
      "Example:\n",
      "// Count users older than 30\n",
      "db.users.countDocuments({ age: { $gt: 30 } });\n",
      "// Count movies in the Comedy genre\n",
      "db.movies.countDocuments({\"genres\": {\"$in\": [\"Comedy\"]}});\n",
      "7. Projection (Selecting Specific Fields)\n",
      "To return specific fields instead of entire documents, use projection.\n",
      "Example:\n",
      "// Find all users but only return names\n",
      "db.users.find({}, { name: 1, _id: 0 });\n",
      "// Find movie titles with Rotten Tomatoes rating above 3\n",
      "db.movies.find({\"tomatoes.viewer.rating\": {\"$gt\": 3}}, {\"_id\": 0, \"title\": 1, \"viewer_rating\":\n",
      "\"$tomatoes.viewer.rating\"});\n",
      "8. Sorting and Limiting Results\n",
      "MongoDB allows sorting and limiting query results using sort() and limit().\n",
      "Example:\n",
      "// Get top 5 oldest users\n",
      "db.users.find().sort({ age: -1 }).limit(5);\n",
      "// Get the movie with the longest runtime\n",
      "db.movies.find({}, {\"_id\": 0, \"title\": 1, \"genres\": 1}).sort({\"runtime\": -1}).limit(1);\n",
      "9. Indexing for Performance Optimization\n",
      "Indexes improve query performance. Use createIndex() to add indexes.\n",
      "Example:\n",
      "// Create an index on the 'name' field\n",
      "db.users.createIndex({ name: 1 });\n",
      "10. Aggregation Pipeline\n",
      "MongoDB supports aggregation for complex data processing.\n",
      "Example:\n",
      "// Group users by city and count them\n",
      "db.users.aggregate([\n",
      "{ $group: { _id: \"$city\", count: { $sum: 1 } } }\n",
      "]);\n",
      "// Count theaters per state\n",
      "db.theaters.aggregate([\n",
      "{ \"$group\": { \"_id\": \"$location.address.state\", \"count\": { \"$sum\": 1 } } },\n",
      "{ \"$project\": { \"state\": \"$_id\", \"count\": 1, \"_id\": 0 } },\n",
      "{ \"$sort\": { \"state\": 1 } }\n",
      "]);\n",
      "// Count movies per year mentioning 'police' in the plot\n",
      "db.movies.aggregate([\n",
      "{ \"$match\": { \"plot\": { \"$regex\": \"police\", \"$options\": \"i\" } } },\n",
      "{ \"$group\": { \"_id\": \"$year\", \"count\": { \"$sum\": 1 } } },\n",
      "{ \"$project\": { \"year\": \"$_id\", \"_id\": 0, \"count\": 1 } },\n",
      "{ \"$sort\": { \"year\": 1 } }\n",
      "]);\n",
      "This guide provides a detailed reference for MongoDB CRUD operations, including additional\n",
      "features for optimizing queries, data processing, and aggregation pipeline examples based on\n",
      "real-world queries.\n",
      "2/19/25\n",
      "Introduction to the Graph Data Model\n",
      "What is a Graph Database?\n",
      "- Data model based on the graph data structure\n",
      "- Composed of nodes and edges\n",
      "- edges connect nodes\n",
      "- each is uniquely identified\n",
      "- each can contain properties (e.g. name, occupation, etc)\n",
      "- supports queries based on graph-oriented operations\n",
      "- traversals\n",
      "- shortest path\n",
      "- lots of others\\\n",
      "Where do Graphs show up?\n",
      "- Social Networks\n",
      "- yes… things like Instagram,\n",
      "- but also… modeling social interactions in fields like psychology and sociology\n",
      "- The Web\n",
      "- it is just a big graph of “pages” (nodes) connected by hyperlinks (edges)\n",
      "- Chemical and biological data\n",
      "- systems biology, genetics, etc.\n",
      "- interaction relationships in chemistry\n",
      "Basics of Graphs and Graph Theory\n",
      "What is a Graph?\n",
      "- Labeled Property Graph\n",
      "- Composed of a set of node (vertex) objects and relationship (edge) objects\n",
      "- Labels are used to mark a node as part of a group\n",
      "- Properties are attributes (think KV pairs) and can exist on nodes and relationships\n",
      "- Nodes with no associated relationships are OK. Edges not connected to nodes are\n",
      "not permitted.\n",
      "-\n",
      "Paths\n",
      "- A path is an ordered sequence of nodes connected by edges in which no nodes or edges\n",
      "are repeated.\n",
      "-\n",
      "Flavors of Graphs\n",
      "- Connected (vs. Disconnected) – there is a path between any two nodes in the graph\n",
      "-\n",
      "- Weighted (vs. Unweighted) – edge has a weight property (important for some\n",
      "algorithms)\n",
      "-\n",
      "- Directed (vs. Undirected) – relationships (edges) define a start and end node\n",
      "-\n",
      "- Acyclic (vs. Cyclic) – Graph contains no cycles\n",
      "-\n",
      "- Sparse vs dense\n",
      "-\n",
      "- Trees\n",
      "-\n",
      "Types of Graph Algorithms - Pathfinding\n",
      "- Pathfinding\n",
      "- finding the shortest path between two nodes, if one exists, is probably the most\n",
      "common operation\n",
      "- “shortest” means fewest edges or lowest weight\n",
      "- Average Shortest Path can be used to monitor efficiency and resiliency of\n",
      "networks.\n",
      "- Minimum spanning tree, cycle detection, max/min flow… are other types of\n",
      "pathfinding\n",
      "BFS vs DFS\n",
      "Shortest Path\n",
      "Types of Graph Algorithms - Centrality & Community Detection\n",
      "- Centrality\n",
      "- determining which nodes are “more important” in a network compared to other\n",
      "nodes\n",
      "-\n",
      "- EX: Social Network Influencers?\n",
      "- Community Detection\n",
      "- evaluate clustering or partitioning of nodes of a graph and tendency to strengthen\n",
      "or break apart\n",
      "Some Famous Graph Algorithms\n",
      "- Dijkstra’s Algorithm - single-source shortest path algo for positively weighted graphs\n",
      "- A* Algorithm - Similar to Dijkstra’s with added feature of using a heuristic to guide\n",
      "traversal\n",
      "- PageRank - measures the importance of each node within a graph based on the number of\n",
      "incoming relationships and the importance of the nodes from those incoming\n",
      "relationships\n",
      "Neo4j\n",
      "- A Graph Database System that supports both transactional and analytical processing of\n",
      "graph-based data\n",
      "- Relatively new class of no-sql DBs\n",
      "- Considered schema optional (one can be imposed)\n",
      "- Supports various types of indexing\n",
      "- ACID compliant\n",
      "- Supports distributed computing\n",
      "- Similar: Microsoft CosmoDB, Amazon Neptune\n",
      "Create docler compose yaml\n",
      "Create env file\n",
      "Enter what is on the slides into them\\\n",
      "Delete existing neo4jcontainer\n",
      "Docker compose up\n",
      "General idea of an llm\n",
      "1. Generate embeddings\n",
      "a. Chunk:\n",
      "i. File name, pdf page, vector\n",
      "b. Chunk stored in redis stack\n",
      "2. User comes along and asks a question\n",
      "a. Generate an embedding for the question\n",
      "i. You get a vector that is based on a question\n",
      "3. Send the vector to redis to get back the chunks that are most similar to the vectorized\n",
      "version of the question\n",
      "a. Can decide on most similar chunks that you want back from redis\n",
      "4. Send back the k most similar chunks as context (mistral model)\n",
      "a. You construct a prompt (text based)\n",
      "5. You get a contextual answer to your class notes (which is the database for this example)\n",
      "6. System is called Rtrical Augmented Generation (RAG)\n",
      "Ollama pull llama3.2:latest\n",
      "Ollama pull mistral:latest\n",
      "Pip install pymupdf\n",
      "Make sure redis stack is running\n",
      "Navigate to source folder\n",
      "Around line 106, tell the computer what model you are using\n",
      "3/12/25\n",
      "AWS Intro\n",
      "Amazon Web Services\n",
      "- Leading Cloud Platform with over 200 different services available\n",
      "- Globally available via its massive networks of regions and availability zones with their\n",
      "massive data centers\n",
      "- Based on a pay-as-you-use cost model.\n",
      "- Theoretically cheaper than renting rackspace/servers in a data center… Theoretically.\n",
      "History of AWS\n",
      "- Originally launched in 2006 with only 2 services: S3 & EC2.\n",
      "- By 2010, services had expanded to include SimpleDB, Elastic Block Store, Relational\n",
      "Database Service, DynamoDB, CloudWatch, Simple Workflow, CloudFront, Availability\n",
      "Zones, and others.\n",
      "- Amazon had competitions with big prizes to spur the adoption of AWS in its early days\n",
      "- They’ve continuously innovated, always introducing new services for ops, dev, analytics,\n",
      "etc… (200+ services now)\n",
      "AWS Service Categories\n",
      "Cloud Models\n",
      "- IaaS (more) - Infrastructure as a Service\n",
      "- Contains the basic services that are needed to build an IT infrastructure\n",
      "- PaaS (more) - Platform as a Service\n",
      "- Remove the need for having to manage infrastructure\n",
      "- You can get right to deploying your app\n",
      "- SaaS (more) - Software as a Service\n",
      "- Provide full software apps that are run and managed by another party/vendor\n",
      "The Shared Responsibility Model - AWS\n",
      "- AWS Responsibilities (Security OF the cloud):\n",
      "- Security of physical infrastructure (infra) and network\n",
      "- keep the data centers secure, control access to them\n",
      "- maintain power availability, HVAC, etc.\n",
      "- monitor and maintain physical networking equipment and global\n",
      "infra/connectivity\n",
      "- Hypervisor & Host OSs\n",
      "- manage the virtualization layer used in AWS compute services\n",
      "- maintaining underlying host OSs for other services\n",
      "- Maintaining managed services\n",
      "- keep infra up to date and functional\n",
      "- maintain server software (patching, etc)\n",
      "The Shared Responsibility Model - Client\n",
      "- Client Responsibilities (Security IN the cloud):\n",
      "- Control of Data/Content\n",
      "- client controls how its data is classified, encrypted, and shared\n",
      "- implement and enforce appropriate data-handling policies\n",
      "- Access Management & IAM\n",
      "- properly configure IAM users, roles, and policies.\n",
      "- enforce the Principle of Least Privilege\n",
      "- Manage self-hosted Apps and associated OSs\n",
      "- Ensure network security to its VPC\n",
      "- Handle compliance and governance policies and procedures\n",
      "The AWS Global Infrastructure\n",
      "- Regions - distinct geographical areas\n",
      "- us-east-1, us-west 1, etc\n",
      "- Availability Zones (AZs)\n",
      "- each region has multiple AZs\n",
      "- roughly equiv to isolated data centers\n",
      "- Edge Locations\n",
      "- locations for CDN and other types of caching services\n",
      "- allows content to be closer to end user.\n",
      "Compute Services\n",
      "- VM-based:\n",
      "- EC2 & EC2 Spot - Elastic Cloud Compute\n",
      "- Container-based:\n",
      "- ECS - Elastic Container Service\n",
      "- ECR - Elastic Container Registry\n",
      "- EKS - Elastic Kubernetes Service\n",
      "- Fargate - Serverless container service\n",
      "- Serverless: AWS Lambda\n",
      "Storage Services\n",
      "- Amazon S3 - Simple Storage Service\n",
      "- Object storage in buckets; highly scalable; different storage classes\n",
      "- Amazon EFS - Elastic File System\n",
      "- Simple, serverless, elastic, “set-and-forget” file system\n",
      "- Amazon EBS - Elastic Block Storage\n",
      "- High-Performance block storage service\n",
      "- Amazon File Cache\n",
      "- High-speed cache for datasets stored anywhere\n",
      "- AWS Backup\n",
      "- Fully managed, policy-based service to automate data protection and compliance\n",
      "of apps on AWS\n",
      "Database Services\n",
      "- Relational - Amazon RDS, Amazon Aurora\n",
      "- Key-Value - Amazon DynamoDB\n",
      "- In-Memory - Amazon MemoryDB, Amazon ElastiCache\n",
      "- Document - Amazon DocumentDB (Compat with MongoDB)\n",
      "- Graph - Amazon Neptune\n",
      "Analytics Services\n",
      "- Amazon Athena - Analyze petabyte scale data where it lives (S3, for example)\n",
      "- Amazon EMR - Elastic MapReduce - Access Apache\n",
      "- Spark, Hive, Presto, etc.\n",
      "- AWS Glue - Discover, prepare, and integrate all your data\n",
      "- Amazon Redshift - Data warehousing service\n",
      "- Amazon Kinesis - real-time data streaming\n",
      "- Amazon QuickSight - cloud-native BI/reporting tool\n",
      "ML and AI services\n",
      "- Amazon SageMaker\n",
      "- fully-managed ML platform, including Jupyter NBs\n",
      "- build, train, deploy ML models\n",
      "- AWS AI Services w/ Pre-trained Models\n",
      "- Amazon Comprehend - NLP\n",
      "- Amazon Rekognition - Image/Video analysis\n",
      "- Amazon Textract - Text extraction\n",
      "- Amazon Translate - Machine translation\n",
      "3/13/25\n",
      "Amazon EC2 & Lambda\n",
      "EC2\n",
      "- EC2 → Elastic Cloud Compute\n",
      "- Scalable Virtual Computing in the Cloud\n",
      "- Many (Many!!) instance types available\n",
      "- Pay-as-you-go model for pricing\n",
      "- Multiple different Operating Systems\n",
      "Features of EC2\n",
      "- Elasticity - easily (and programmatically) scale instances up or down as needed\n",
      "- You can use one of the standard AMIs OR provide your own AMI if pre-config is needed\n",
      "- Easily integrates with many other services such as S3, RDS, etc.\n",
      "- AMI = amazon machine image\n",
      "-\n",
      "EC2 Lifecycle\n",
      "- Launch - when starting an instance for the first time with a chosen configuration\n",
      "- Start/Stop - Temporarily suspend usage without deleting the instance\n",
      "- Terminate - Permanently delete the instance\n",
      "- Reboot - Restart an instance without sling the data on the root volume\n",
      "Where can you store data?\n",
      "- Instance Store: Temporary, high-speed storage tied to the instance lifecycle\n",
      "- EFS (Elastic File System) Support - Shared file storage\n",
      "- EBS (Elastic Block Storage) - Persistent block-level storage\n",
      "- S3 - large data set storage or EC2 backups even\n",
      "Common EC2 Use Cases\n",
      "- Web Hosting - Run a website/web server and associated apps\n",
      "- Data Processing - It’s a VM… you can do anything to data possible with a programming\n",
      "language.\n",
      "- Machine Learning - Train models using GPU instances\n",
      "- Disaster Recovery - Backup critical workloads or infrastructure in the cloud\n"
     ]
    }
   ],
   "source": [
    "experiment_results = pd.read_csv(\"results/experiment_results.csv\")\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Directory 'static/' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m\n\u001b[1;32m      2\u001b[0m doc \u001b[38;5;241m=\u001b[39m fitz\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Practical 01 (1).pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m text_by_page \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fitz/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfrontend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mop\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/frontend/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/frontend/events/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclipboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_mixins\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhash_change\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/frontend/events/clipboard.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_mixins\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClipboardDataMixin\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Event\n\u001b[1;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClipboardEvent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClipboardEvent\u001b[39;00m(Event, ClipboardDataMixin):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/frontend/dom.py:439\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatcher\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/frontend/dispatcher.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstarlette\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mendpoints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebSocketEndpoint\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstarlette\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebsockets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebSocket\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, server\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m later_await\n\u001b[1;32m     18\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreact\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/frontend/server.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m app: Any \u001b[38;5;241m=\u001b[39m Starlette(debug\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mDEBUG)\n\u001b[0;32m---> 24\u001b[0m app\u001b[38;5;241m.\u001b[39mmount(config\u001b[38;5;241m.\u001b[39mSTATIC_ROUTE, StaticFiles(directory\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mSTATIC_DIRECTORY), name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mSTATIC_NAME)\n\u001b[1;32m     25\u001b[0m app\u001b[38;5;241m.\u001b[39madd_middleware(GZipMiddleware)\n\u001b[1;32m     26\u001b[0m app\u001b[38;5;241m.\u001b[39madd_middleware(\n\u001b[1;32m     27\u001b[0m     CORSMiddleware,\n\u001b[1;32m     28\u001b[0m     allow_origins\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     allow_headers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     32\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/starlette/staticfiles.py:56\u001b[0m, in \u001b[0;36mStaticFiles.__init__\u001b[0;34m(self, directory, packages, html, check_dir, follow_symlink)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_symlink \u001b[38;5;241m=\u001b[39m follow_symlink\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_dir \u001b[38;5;129;01mand\u001b[39;00m directory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(directory):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Directory 'static/' does not exist"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "doc = fitz.open(\"data/Practical 01 (1).pdf\")\n",
    "text_by_page = []\n",
    "for page_num, page in enumerate(doc):\n",
    "    text_by_page.append((page_num, page.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'DS 4300 - Spring 2025  \\nPractical 02 \\n \\nDue:  \\n-\\u200b\\nProject needs to be functional for Exam on March 24. \\n-\\u200b\\nFinal deliverable and repo to be submitted by March 26 @ 11:59pm.  \\n \\nOverview: \\n \\nIn this project, you and your team will build a local Retrieval-Augmented Generation \\nsystem that allows a user to query the collective DS4300 notes from members of your \\nteam.  Your system will do the following: \\n \\n1.\\u200b Ingest a collection of documents that represent material, such as course notes, \\nyou and your team have collected throughout the semester.  \\n2.\\u200b Index those documents using embedding and a vector database \\n3.\\u200b Accept a query from the user.  \\n4.\\u200b Retrieve relevant context based on the user’s query \\n5.\\u200b Package the relevant context up into a prompt that is passed to a locally-running \\nLLM to generate a response.  \\n \\nIn this, you’ll experiment with different variables - chunking strategies, embedding models, \\nsome prompt engineering, local LLM, and vector database options.  You’ll analyze how \\nthese changes affect the system’s performance and output quality.  \\n \\nTeams and Corpus: \\n \\nEach team should be composed of 2 - 4 members.  They can be the same as Practical \\n01, but teams may switch up.  \\n \\nEach team should gather a collection of course notes taken by the team members.  This \\ncan be the slide decks, personal notes taken throughout, and additional documentation \\nfor the tools/systems we have used.   \\n \\nTools: \\n \\n-\\u200b\\nPython for building the pipeline \\n-\\u200b\\nOllama for running LLMs locally (you’ll compare and contrast at least 2 different \\n'), (1, 'models \\n-\\u200b\\nVector Databases (Redis Vector DB, Chroma, and one other of your choosing) \\n-\\u200b\\nEmbedding Models (you’ll compare and contrast at least 3 different options)   \\n \\nVariables to Explore: \\n \\n1.\\u200b Text preprocessing & chunking  \\na.\\u200b Try various size chunks: 200, 500, 1000 tokens, for example \\nb.\\u200b Try different chunk overlap sizes: 0, 50, 100 token overlap for example \\nc.\\u200b Try various basic text prep strategies such as removing whitespace, \\npunctuation, and any other “noise”.  \\n2.\\u200b Embedding Models - Choose 3 to compare and contrast. Examples include:  \\na.\\u200b sentence-transformers/all-MiniLM-L6-v2 \\nb.\\u200b sentence-transformers/all-mpnet-base-v2 \\nc.\\u200b InstructorXL \\nd.\\u200b The model we used in class \\nMeasure interesting properties of using the various embedding models such as \\nspeed, memory usage, and retrieval quality (qualitative).  \\n3.\\u200b Vector Database - At a minimum, compare and contrast Redis Vector DB and \\nChroma (you’ll have to do a little research on this db) and one other vector \\ndatabase you choose based on research.  Examine the speed of indexing and \\nquerying as well as the memory usage.  \\n4.\\u200b Tweaks to the System prompt. Use the one from the class example as a starting \\npoint.  \\n5.\\u200b Try at least 2 different local LLMs.  Examples include Llama 2 7B and Mistral 7B.  \\nYou aren’t required to use these two specifically, however.  \\n \\nSuggested Steps: \\n \\n1.\\u200b Collect and clean the data.   \\na.\\u200b If you’re using PDFs, review the output of whichever Python PDF library \\nyou’re using.  Is it what you expect?  \\nb.\\u200b Do you want to pre-process the raw text in some way before indexing?  \\nPerhaps remove extra white space or remove stop words? \\n2.\\u200b Implement a driver Python script to execute your various versions of the indexing \\npipeline and to collect important data about the process (memory, time, etc).  \\nSystematically vary the chunking strategies, embedding models, various prompt \\ntweaks, choice of Vector DB, and choice of LLM.  \\n3.\\u200b Develop a set of user questions that you give to each pipeline and qualitatively \\n'), (2, 'review the responses.  \\n4.\\u200b Choose which pipeline you think works the best, and justify your choice.  \\n \\nDeliverables: \\n \\nAs a team, you’ll produce a slide deck communicating your findings as well as your final \\nchoice of pipelines with justification. Be specific.  (Template for deck will be forthcoming.) \\n \\nYou will also include a public GitHub repository containing well-organized set of scripts \\nrelated to the various pipelines your team tests.  The README should describe how to \\nexecute your project.   \\n \\nMore details on deliverables will be shared soon.  \\n \\n \\nAreas for Evaluation: \\n1.\\u200b Robustness of Experimentation (30%) \\n2.\\u200b Analysis of collected data (30%) \\n3.\\u200b Recommendation of pipeline organizations (20%) \\n4.\\u200b Professionalism of Slide Deck (20%) \\n')]\n"
     ]
    }
   ],
   "source": [
    "print(text_by_page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
