{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS 4300 - Spring 2025\n",
      "Practical 02\n",
      "Due:\n",
      "- Project needs to be functional for Exam on March 24.\n",
      "- Final deliverable and repo to be submitted by March 26 @ 11:59pm.\n",
      "Overview:\n",
      "In this project, you and your team will build a local Retrieval-Augmented Generation\n",
      "system that allows a user to query the collective DS4300 notes from members of your\n",
      "team. Your system will do the following:\n",
      "1. Ingest a collection of documents that represent material, such as course notes,\n",
      "you and your team have collected throughout the semester.\n",
      "2. Index those documents using embedding and a vector database\n",
      "3. Accept a query from the user.\n",
      "4. Retrieve relevant context based on the user’s query\n",
      "5. Package the relevant context up into a prompt that is passed to a locally-running\n",
      "LLM to generate a response.\n",
      "In this, you’ll experiment with different variables - chunking strategies, embedding models,\n",
      "some prompt engineering, local LLM, and vector database options. You’ll analyze how\n",
      "these changes affect the system’s performance and output quality.\n",
      "Teams and Corpus:\n",
      "Each team should be composed of 2 - 4 members. They can be the same as Practical\n",
      "01, but teams may switch up.\n",
      "Each team should gather a collection of course notes taken by the team members. This\n",
      "can be the slide decks, personal notes taken throughout, and additional documentation\n",
      "for the tools/systems we have used.\n",
      "Tools:\n",
      "- Python for building the pipeline\n",
      "- Ollama for running LLMs locally (you’ll compare and contrast at least 2 different\n",
      "models\n",
      "- Vector Databases (Redis Vector DB, Chroma, and one other of your choosing)\n",
      "- Embedding Models (you’ll compare and contrast at least 3 different options)\n",
      "Variables to Explore:\n",
      "1. Text preprocessing & chunking\n",
      "a. Try various size chunks: 200, 500, 1000 tokens, for example\n",
      "b. Try different chunk overlap sizes: 0, 50, 100 token overlap for example\n",
      "c. Try various basic text prep strategies such as removing whitespace,\n",
      "punctuation, and any other “noise”.\n",
      "2. Embedding Models - Choose 3 to compare and contrast. Examples include:\n",
      "a. sentence-transformers/all-MiniLM-L6-v2\n",
      "b. sentence-transformers/all-mpnet-base-v2\n",
      "c. InstructorXL\n",
      "d. The model we used in class\n",
      "Measure interesting properties of using the various embedding models such as\n",
      "speed, memory usage, and retrieval quality (qualitative).\n",
      "3. Vector Database - At a minimum, compare and contrast Redis Vector DB and\n",
      "Chroma (you’ll have to do a little research on this db) and one other vector\n",
      "database you choose based on research. Examine the speed of indexing and\n",
      "querying as well as the memory usage.\n",
      "4. Tweaks to the System prompt. Use the one from the class example as a starting\n",
      "point.\n",
      "5. Try at least 2 different local LLMs. Examples include Llama 2 7B and Mistral 7B.\n",
      "You aren’t required to use these two specifically, however.\n",
      "Suggested Steps:\n",
      "1. Collect and clean the data.\n",
      "a. If you’re using PDFs, review the output of whichever Python PDF library\n",
      "you’re using. Is it what you expect?\n",
      "b. Do you want to pre-process the raw text in some way before indexing?\n",
      "Perhaps remove extra white space or remove stop words?\n",
      "2. Implement a driver Python script to execute your various versions of the indexing\n",
      "pipeline and to collect important data about the process (memory, time, etc).\n",
      "Systematically vary the chunking strategies, embedding models, various prompt\n",
      "tweaks, choice of Vector DB, and choice of LLM.\n",
      "3. Develop a set of user questions that you give to each pipeline and qualitatively\n",
      "review the responses.\n",
      "4. Choose which pipeline you think works the best, and justify your choice.\n",
      "Deliverables:\n",
      "As a team, you’ll produce a slide deck communicating your findings as well as your final\n",
      "choice of pipelines with justification. Be specific. (Template for deck will be forthcoming.)\n",
      "You will also include a public GitHub repository containing well-organized set of scripts\n",
      "related to the various pipelines your team tests. The README should describe how to\n",
      "execute your project.\n",
      "More details on deliverables will be shared soon.\n",
      "Areas for Evaluation:\n",
      "1. Robustness of Experimentation (30%)\n",
      "2. Analysis of collected data (30%)\n",
      "3. Recommendation of pipeline organizations (20%)\n",
      "4. Professionalism of Slide Deck (20%)\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "with pdfplumber.open(\"Practical 01 (1).pdf\") as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
